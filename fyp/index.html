<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Improve learning resource recommendations for students</title>

		<meta name="description" content="An evaluation of machine learning algorihtms on a educational corpus">
		<meta name="author" content="Cathal Geoghegan">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/night.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">
		<link rel="stylesheet" href="css/custom.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h1><small>Improving learning resource recommendations for students</small></h1>
					<p>
						<small>Created by <a href="http://CathalGeoghegan.me">Cathal Geoghegan</a> / <a href="http://twitter.com/_Kotl">@_Kotl</a></small>
					</p>
					<aside class="notes">
        				Welcome everyone.
						Introduce yourself.
						Brief intro to why you choose this topic ~Fred -> recommendations
						Passionate about education.
    				</aside>
				</section>
				<section>
					<section>
						<h3>Introduction</h3>
                        <!-- I would say that you want to strip out the narrative elements. Reduce to bullet points ~AOC -->
                        <!-- might be worth putting in logos or pictures to help view. -->
                        <!-- sorry if I broke the coe 0_o -->
						<p class="fragment">
	                        Investigating the use of <b>machine learning algorithms</b> to generate <b>recommendations</b> from an <b>educational corpus</b>.<br />
	                        Focusing mainly on:<br />
                        	<ul class="fragment">
								<li> LDA,</li>
								<li> k-NN</li>
								<li> Word2Vec.</li>
							</ul>
						</p>
                    	<ul class="fragment">
							<li>Temporal Performance</li>
							<li> The quality of recommendations</li>
						</ul>
						<p class="fragment">
							On a collection of 30,000 papers from arXiv.
						</p>
						<aside class="notes">
							<p>Used arXiv as a proxy to an educational corpus. Academic papers are an educational
							source but have their own writing style compared to lecture notes, videos etc.</p>
							<p>arXiv corpus contains a mixture of papers from physics, maths, computer science.
							The vast majority however are related to physics.</p><p>Looking at the time to train the model</p>
							<p>Quality of recommendations is subjective</p>
	    				</aside>
					</section>
					<section>
						<h3>Motivation</h3>
						<p class="fragment">
							The internet has proved an invaluable tool in providing access to knowledge. However the volume of data is far too large to be finely catalogued by humans. For this we need to use machines to automate the task.
						</p>
						<p class="fragment">
							The overall aim of this is to try and choose a model to use when generating recommendations for students.
						</p>
						<aside class="notes">
							<p>We are currently seeing the rise of the MOOC.</p>
							<p>Google is still the goto place to find information</p>
							<p>Hyperlinks are still a very important bridge between topics</p>
							<p>Use machine learning algorithms to bridge the gap between documents concerning
								similar topics</p>
						</aside>
					</section>
				</section>
				<section>
					<h3>Outline</h3>
					<ul>
						<li class="fragment">What is machine learning</li>
						<li class="fragment">What is currently being done in this field</li>
						<li class="fragment">What I hope to achieve with my FYP</li>
						<li class="fragment">Preliminary results</li>
						<li class="fragment">Questions</li>
					</ul>
				</section>
				<section>
					<section>
						<h3>Machine Learning</h3>
						<p class="fragment">
							Machine learning is an interdisciplinary field dedicated to the study of self learning systems. There are three types of machine learning.
						</p>
						<ul>
							<li class="fragment">Supervised Learning</li>
							<li class="fragment">Reinforced Learning</li>
							<li class="fragment">Unsupervised Learning</li>
						</ul>
						<aside class="notes">
							<p>ML touches upon numerous different areas; nlp, ir, vision, game theory, statistics,
							 	ai, maths</p>
						</aside>
					</section>
					<section>
						<h3>Supervised Learning</h3>
						<p class="fragment">
							The machine is fed inputs <em class="model">x1, x2...xZ</em><!-- consider a more obvious different font ? -->,
							desired outputs <em class="model">y1, y2...yZ</em> and then tries to create a model which fits inputs to outputs.
						</p>
						<p class="fragment">
							A large number of training examples are required to properly train a supervised model. For this reason I choose not to use this approach.
						</p>
						<aside class="notes">
							<p>Due to time constraints it wouldn't have been feasable to find an annotated data set or
							to find a labelled one.</p>
							<p>There are hundreds of different approaches using sl; neural networks, svm, regression, etc.</p>
						</aside>
					</section>
					<section>
						<h3>Reinforced Learning</h3>
						<p class="fragment">
							The machine interacts with the environment and produces actions <em class="model">a1, a2...aZ</em> which affects the environment. The machine then receives rewards <em class="model">r1, r2...rZ</em> and then tries to learn to produce actions which maximises future rewards.
						</p>
						<p class="fragment">
							Like supervised learning this would require a large number of training samples to produce a working model and was not used in this project.
                        </p><!-- more importantly, we didn't have a clear reward function and it wasn't a real-time problem -->
						<aside class="notes">
							<p>More importantly we didn't have a clear rewards function, real-time problem</p>
						</aside>
					</section>
					<section>
						<h3>Unsupervised Learning</h3>
						<p class="fragment">
							The machine is fed inputs <em class="model">x1, x2...xZ</em> and tries to build a model that finds patterns in the data. No desired outputs nor rewards are needed.
						</p>
						<p class="fragment">
							This type of machine learning is the focus of my project. Each of the algorithms used builds a probabilistic model of the data which it can then use for inference.
						</p>
						<aside class="notes">
							<p>Unsupervised are largely probabilistic models. Tries to find hidden patterns in
							the data.</p>
						</aside>
					</section>
				</section>
				<section>
					<section>
						<h3>State of the Art</h3>
						<ul>
							<li class="fragment">1990, Deerwester introduced the concept of latent semantic indexing.</li>
							<li class="fragment">2003, Blei and Ng built upon the work done previously by Deerwester to discover Latent dirichlet allocation.</li>
							<li class="fragment">2008, Knowledge and Information Systems listed k-NN as one of the top data-mining algorithms.</li>
							<li class="fragment">2014, Word2Vec released as an efficient algorithm to calculate vector representations of words.
						</ul>
					</section>
					<section>
						<h3>Technology</h3>
						<img class="logos" data-src="imgs/logo-gensim.png" alt="Gensim Logo">
						<p>
							<em>Gensim</em>: a python library to conduct unsupervised semantic modeling of plain text.
						</p>
						<aside class="notes">
							<p>Originally created to find similar articles for the Czech Digital Mathematics Library. Later
							became the PhD research project for the libraries creator.</p>
						</aside>
					</section>
					<section>
						<h3>Technology</h3>
						<img class="logos" data-src="imgs/logo-annoy.png" alt="Annoy img">
						<p>
							<em>Annoy</em>: a C++/Python library created by Spotify to calculate approximate nearest neighbors.
						</p>
						<aside class="notes">
							Was created at a Spotify hackathon.
							Is used internally to generated recommendations for users. ~> Millions of songs on
							platform.
							Uses locality-sensitive-hashing to group together similar items. In particular it
							uses random projection to do this (cosine similarity between items).
						</aside>
					</section>
				</section>
				<section>
					<section>
						<h3>Main objective</h3>
						<p class="fragment">
							Can we identify the best algorithm for learning resource recommendations?
						</p>
					</section>
					<section>
						<h4>Objective 1</h4>
						<p>
							Build a corpus of 30,000 academic papers to act as a proxy for learning resources.
						</p>
					</section>
					<section>
						<h4>Objective 2</h4>
						<p>
							Evaluate the temporal performance of each of the algorithms.
						</p>
						<aside class="notes">
							Currently looking at the temporal performance to generate the models but could look
							at the performance of generating recomendations.
						</aside>
					</section>
					<section>
						<h4>Objective 3</h4>
						<p>
							Rank the quality of recommendations generated by the algorithms.
						</p>
					</section>
					<section>
						<h4>Objective 4</h4>
						<p>
							Compare the results to available meta-data.
						</p>
						<aside class="notes">
							For each paper we know what general category it belongs to so we would expect recomendations
							generated to be in similar categories.
						</aside>
					</section>
				</section>
				<section>
					<h3>Preliminary Results</h3>
				</section>
				<section>
					<section>
						<h3>LDA</h3>
						<p class="fragment">
							A model where documents contain a mixture of topics.
						</p>
						<p class="fragment">
							Topics are a mixture of word probabilities.
						</p>
						<p class="fragment">
							Model assumes that the topics are generated first and then the documents are generated from the topics.
						</p>
						<p class="fragment">
							Inferring the topics is a reversing of the generation process.
						</p>
					</section>
					<!-- Mention that the time is using a log scale -->
					<section>
						<p>
							<img data-src="imgs/lda_total_time.png" alt="LDA Total Time">
						</p>
					</section>
					<section>
						<h3>Topic Samples</h3>
						<p>
							<img data-src="imgs/topic1.png" alt="Topic1">
						</p>
					</section>
					<section>
						<h3>Topic Samples</h3>
						<p>
							<img data-src="imgs/topic2.png" alt="Topic2">
						</p>
					</section>
					<section>
						<h3>Topic Samples</h3>
						<p>
							<img data-src="imgs/topic3.png" alt="Topic3">
						</p>
					</section>
					<section>
						<h3>Topic Samples</h3>
						<p>
							<img data-src="imgs/topic4.png" alt="Topic4">
						</p>
					</section>
					<section>
						<h3>Topic Samples</h3>
						<p>
							<img data-src="imgs/topic5.png" alt="Topic5">
						</p>
					</section>
				</section>
				<section>
					<section>
						<h3>k-Nearest-Neighbors</h3>
						<p class="fragment">
							A classification algorithm that finds groups of k objects nearest to an input value.
						</p>
						<p class="fragment">
							Assumes that objects that are close in feature space are the same.
						</p>
						<p class="fragment">
							Suffers from the curse of dimensionality when the features space is large.
						</p>
						<p class="fragment">
							Spotify's Annoy approximate-Nearest-Neighbor library was used for k-NN queries.
						</p>
					</section>
					<!-- Mention that the time is using a log scale -->
					<section>
						<p>
							<img data-src="imgs/knn_total_time.png" alt="KNN Total Time">
						</p>
					</section>
				</section>
				<section>
					<section>
						<h3>Word2Vec</h3>
						<p class="fragment">
							An algorithm that uses unsupervised neural-networks to learn the meaning behind words.
						</p>
						<p class="fragment">
							Uses two learning algorithms, continuous bag of words or a continuous skip-gram.
						</p>
						<p class="fragment">
							Can use algebraic operations on the resulting word vectors to find words close in word vector space.
						</p>
					</section>
					<section>
						<h4>Operations</h4>
						<p class="fragment">
							<em>vector('king') - vector('man') + vector('woman') -> 'queen'</em>
						</p>
						<p class="fragment">
							<em>vector('biggest') − vector('big') + vector('small') -> 'smallest'</em>
						</p>
						<p class="fragment">
							<em>vector('Berlin') - vector('Germany') + vector('France) - > 'Paris'
							</em>
						</p>
					</section>
				</section>
				<section>
					<section>
						<h2>Comparison</h2>
					</section>
					<section>
						<p>
							<img data-src="imgs/algo_comparison.png" alt="comparison train time">
						</p>
					</section>
				</section>
				<section>
					<h2>Questions?</h2>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
